{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from pytorch_nlp_models.text_pair.siamese_rnn import SiameseGRU\n",
    "from utils.datasets import LCQMCDataset\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "LCQMC_PATH = os.path.join(DATA_PATH, 'LCQMC')\n",
    "WORD_VECTORS_PATH = os.path.join(DATA_PATH, 'word_vectors')\n",
    "BAIDUBAIKE_PKL = os.path.join(WORD_VECTORS_PATH, 'baidubaike.pkl')\n",
    "\n",
    "MAX_SEQ_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BAIDUBAIKE_PKL, 'rb') as f:\n",
    "    wvs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = wvs['iw']\n",
    "wi = wvs['wi']\n",
    "dim = wvs['dim']\n",
    "emb = wvs['emb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SiameseGRU(\n",
       "  (emb): Embedding(635976, 300, padding_idx=0)\n",
       "  (rnn): GRU(300, 300, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=1800, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = SiameseGRU(vocab_size=len(iw), emb_dim=dim)\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单样本前向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LCQMCDataset(LCQMC_PATH, MAX_SEQ_LEN, wi, charmode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to('dev')\n",
    "sample = dataset[1]\n",
    "ids1 = sample['ids1'].view(1, -1)\n",
    "ids2 = sample['ids2'].view(1, -1)\n",
    "len1 = sample['len1'].view(1)\n",
    "len2 = sample['len2'].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids1': tensor([ 1600,  2112,   722,   131,     9,  2459, 14299,   986,   855,  1768,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'ids2': tensor([  799,  2468,    67,  2519,  1678,  1600,  5771,    73,   128,  7964,\n",
       "             9, 10388, 11774,  2320,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'len1': tensor(10),\n",
       " 'len2': tensor(14),\n",
       " 'label': tensor(0.)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, out1, out2 = rnn(ids1, ids2, len1, len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1109, 0.0897]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(logits, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 600]), torch.Size([1, 600]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape, out2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch前向\n",
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "data_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 40]), torch.Size([10]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['ids1'].shape, batch['len1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 1., 0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, out1, out2 = rnn(batch['ids1'], batch['ids2'], batch['len1'], batch['len2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1567,  0.2015],\n",
       "        [ 0.1109,  0.0897],\n",
       "        [-0.0912,  0.1984],\n",
       "        [ 0.0875,  0.0019],\n",
       "        [ 0.0724, -0.0284],\n",
       "        [-0.0634,  0.4135],\n",
       "        [-0.1382,  0.1250],\n",
       "        [ 0.1263,  0.0430],\n",
       "        [-0.0361,  0.0125],\n",
       "        [-0.0380, -0.0245]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4888, 0.5112],\n",
       "        [0.5053, 0.4947],\n",
       "        [0.4281, 0.5719],\n",
       "        [0.5214, 0.4786],\n",
       "        [0.5252, 0.4748],\n",
       "        [0.3830, 0.6170],\n",
       "        [0.4346, 0.5654],\n",
       "        [0.5208, 0.4792],\n",
       "        [0.4879, 0.5121],\n",
       "        [0.4966, 0.5034]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim = 1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.5112, 0.5053, 0.5719, 0.5214, 0.5252, 0.6170, 0.5654, 0.5208, 0.5121,\n",
       "        0.5034], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(probs, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ids1 = batch['ids1']\n",
    "batch_ids2 = batch['ids2']\n",
    "batch_len1 = batch['len1']\n",
    "batch_len2 = batch['len2']\n",
    "_logits_list = []\n",
    "for i in range(batch_size):\n",
    "    _ids1 = batch_ids1[i].view(1, -1)\n",
    "    _ids2 = batch_ids2[i].view(1, -1)\n",
    "    _len1 = batch_len1[i].view(1)\n",
    "    _len2 = batch_len2[i].view(1)\n",
    "    _lg, _, _ = rnn(_ids1, _ids2, _len1, _len2)\n",
    "    _logits_list.append(_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1567,  0.2015],\n",
       "        [ 0.1109,  0.0897],\n",
       "        [-0.0912,  0.1984],\n",
       "        [ 0.0875,  0.0019],\n",
       "        [ 0.0724, -0.0284],\n",
       "        [-0.0634,  0.4135],\n",
       "        [-0.1382,  0.1250],\n",
       "        [ 0.1263,  0.0430],\n",
       "        [-0.0361,  0.0125],\n",
       "        [-0.0380, -0.0245]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits = torch.cat(_logits_list, dim = 0)\n",
    "_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4888, 0.5112],\n",
       "        [0.5053, 0.4947],\n",
       "        [0.4281, 0.5719],\n",
       "        [0.5214, 0.4786],\n",
       "        [0.5252, 0.4748],\n",
       "        [0.3830, 0.6170],\n",
       "        [0.4346, 0.5654],\n",
       "        [0.5208, 0.4792],\n",
       "        [0.4879, 0.5121],\n",
       "        [0.4966, 0.5034]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs = torch.softmax(_logits, dim = 1)\n",
    "_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch前向 vs one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00],\n",
       "        [-5.9605e-08,  2.9802e-08],\n",
       "        [-2.9802e-08,  0.0000e+00],\n",
       "        [ 0.0000e+00, -5.9605e-08],\n",
       "        [-5.9605e-08, -2.9802e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  2.9802e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00],\n",
       "        [ 2.9802e-08,  0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_probs - probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9802e-08, -5.9605e-08],\n",
       "        [-1.0431e-07,  2.2352e-08],\n",
       "        [-5.2154e-08, -1.4901e-08],\n",
       "        [ 3.7253e-08, -1.1176e-07],\n",
       "        [-2.2352e-08,  3.7253e-09],\n",
       "        [ 1.0431e-07,  5.9605e-08],\n",
       "        [ 2.9802e-08, -1.4901e-08],\n",
       "        [ 0.0000e+00,  2.2352e-08],\n",
       "        [-1.4901e-08,  1.1176e-08],\n",
       "        [-7.4506e-09, -4.0978e-08]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits - logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = SiameseGRU(vocab_size=len(iw), emb_dim=dim, \n",
    "                 emb_weights=  torch.tensor(emb, dtype = torch.float32),\n",
    "                 emb_static=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1045, -0.4096,  0.0025,  ...,  0.2424,  0.5210,  0.0380],\n",
       "        ...,\n",
       "        [ 0.1317, -0.0819,  0.0877,  ..., -0.0862, -0.0418, -0.1139],\n",
       "        [ 0.0918,  0.1966, -0.0043,  ..., -0.1252,  0.0385,  0.0049],\n",
       "        [ 0.0351,  0.1157, -0.0244,  ..., -0.0970,  0.0307, -0.0839]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.emb.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1045, -0.4096,  0.0025,  ...,  0.2424,  0.5210,  0.0380],\n",
       "        ...,\n",
       "        [ 0.1317, -0.0819,  0.0877,  ..., -0.0862, -0.0418, -0.1139],\n",
       "        [ 0.0918,  0.1966, -0.0043,  ..., -0.1252,  0.0385,  0.0049],\n",
       "        [ 0.0351,  0.1157, -0.0244,  ..., -0.0970,  0.0307, -0.0839]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
